"""
Day 6 æµ‹è¯•ï¼šå›æµ‹è¿›é˜¶å’Œä¼˜åŒ–
"""

import sys
import os
from datetime import datetime, timedelta
from pathlib import Path

sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

import apexquant as aq
from apexquant.data import DataManager
from apexquant.backtest import BacktestRunner
from apexquant.backtest.strategy import MAStrategy
from apexquant.backtest.optimizer import ParameterOptimizer
from apexquant.backtest.monte_carlo import MonteCarloSimulator
from apexquant.backtest.ai_analyzer import AIBacktestAnalyzer
import pandas as pd
import numpy as np


def get_test_data():
    """è·å–æµ‹è¯•æ•°æ®"""
    manager = DataManager(data_dir="data")
    end_date = datetime.now()
    start_date = end_date - timedelta(days=180)
    
    df = manager.fetch_and_store_bars(
        symbol='600519.SH',
        start_date=start_date.strftime('%Y%m%d'),
        end_date=end_date.strftime('%Y%m%d')
    )
    
    return df


def test_grid_search():
    """æµ‹è¯•ç½‘æ ¼æœç´¢"""
    print("\n" + "="*60)
    print("æµ‹è¯• 1: ç½‘æ ¼æœç´¢å‚æ•°ä¼˜åŒ–")
    print("="*60)
    
    if not aq.is_core_loaded():
        print("âš ï¸  C++ æ¨¡å—æœªåŠ è½½ï¼Œè·³è¿‡")
        return True
    
    df = get_test_data()
    if df.empty or len(df) < 50:
        print("âŒ æ•°æ®ä¸è¶³")
        return False
    
    # å‚æ•°ç½‘æ ¼
    param_grid = {
        'short_window': [3, 5, 7],
        'long_window': [15, 20, 25]
    }
    
    print(f"\nå‚æ•°ç½‘æ ¼: {param_grid}")
    print(f"ç»„åˆæ•°: {len(param_grid['short_window']) * len(param_grid['long_window'])}")
    
    # æ³¨æ„ï¼šè¿™é‡Œç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥ä½¿ç”¨å¹¶è¡Œ
    # ç”±äºå¹¶è¡Œéœ€è¦å¯åºåˆ—åŒ–çš„å¯¹è±¡ï¼Œè¿™é‡Œç”¨ä¸²è¡Œæ¼”ç¤º
    optimizer = ParameterOptimizer(objective='sharpe_ratio')
    
    best_params = None
    best_score = -np.inf
    
    for sw in param_grid['short_window']:
        for lw in param_grid['long_window']:
            if sw >= lw:
                continue
            
            try:
                strategy = MAStrategy(short_window=sw, long_window=lw)
                runner = BacktestRunner(initial_capital=1000000.0)
                result = runner.run(strategy, df)
                
                score = result.sharpe_ratio
                
                print(f"  SW={sw}, LW={lw}: å¤æ™®={score:.3f}, æ”¶ç›Š={result.total_return:.2%}")
                
                if score > best_score:
                    best_score = score
                    best_params = {'short_window': sw, 'long_window': lw}
            except:
                pass
    
    if best_params:
        print(f"\nâœ“ æœ€ä½³å‚æ•°: {best_params}")
        print(f"  æœ€ä½³å¤æ™®æ¯”ç‡: {best_score:.3f}")
        return True
    else:
        print("âŒ ä¼˜åŒ–å¤±è´¥")
        return False


def test_monte_carlo():
    """æµ‹è¯•è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ"""
    print("\n" + "="*60)
    print("æµ‹è¯• 2: è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ")
    print("="*60)
    
    if not aq.is_core_loaded():
        print("âš ï¸  C++ æ¨¡å—æœªåŠ è½½ï¼Œè·³è¿‡")
        return True
    
    df = get_test_data()
    if df.empty:
        print("âŒ æ•°æ®ä¸è¶³")
        return False
    
    # è¿è¡ŒåŸºå‡†å›æµ‹
    strategy = MAStrategy(short_window=5, long_window=20)
    runner = BacktestRunner(initial_capital=1000000.0)
    result = runner.run(strategy, df)
    
    print(f"\nåŸºå‡†ç­–ç•¥:")
    print(f"  æ”¶ç›Šç‡: {result.total_return:.2%}")
    print(f"  å¤æ™®æ¯”ç‡: {result.sharpe_ratio:.3f}")
    
    # è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ
    print(f"\nè’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ (åŸºäºå†å²æ”¶ç›Šç‡)...")
    simulator = MonteCarloSimulator(n_simulations=100, n_days=len(df))
    
    if result.daily_returns:
        simulated_paths = simulator.simulate_from_returns(
            result.daily_returns,
            initial_value=1000000.0
        )
        
        analysis = simulator.analyze_results(simulated_paths)
        
        print(f"\næ¨¡æ‹Ÿç»“æœç»Ÿè®¡:")
        print(f"  å‡å€¼ç»ˆå€¼: {analysis['mean_final_value']:,.0f}")
        print(f"  ä¸­ä½æ•°ç»ˆå€¼: {analysis['median_final_value']:,.0f}")
        print(f"  5% åˆ†ä½æ•°: {analysis['percentile_5']:,.0f}")
        print(f"  95% åˆ†ä½æ•°: {analysis['percentile_95']:,.0f}")
        print(f"  äºæŸæ¦‚ç‡: {analysis['probability_loss']:.2%}")
        
        # ç»˜å›¾
        output_dir = Path("output")
        output_dir.mkdir(exist_ok=True)
        
        simulator.plot_paths(
            n_paths=50,
            save_path=str(output_dir / "monte_carlo_paths.png")
        )
        
        print(f"\nâœ“ è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿå®Œæˆ")
        return True
    else:
        print("âŒ æ²¡æœ‰æ”¶ç›Šç‡æ•°æ®")
        return False


def test_ai_analysis():
    """æµ‹è¯• AI åˆ†æ"""
    print("\n" + "="*60)
    print("æµ‹è¯• 3: AI å›æµ‹åˆ†æ")
    print("="*60)
    
    if not aq.is_core_loaded():
        print("âš ï¸  C++ æ¨¡å—æœªåŠ è½½ï¼Œè·³è¿‡")
        return True
    
    # è®¾ç½® API
    api_key = os.getenv('DEEPSEEK_API_KEY', 'sk-eea85ceb681c46a3bfbd4903a44ecc2d')
    
    df = get_test_data()
    if df.empty:
        print("âŒ æ•°æ®ä¸è¶³")
        return False
    
    # è¿è¡Œå›æµ‹
    strategy = MAStrategy(short_window=5, long_window=20)
    runner = BacktestRunner(initial_capital=1000000.0)
    result = runner.run(strategy, df)
    
    print(f"\nç­–ç•¥è¡¨ç°:")
    print(f"  æ”¶ç›Šç‡: {result.total_return:.2%}")
    print(f"  å¤æ™®æ¯”ç‡: {result.sharpe_ratio:.3f}")
    print(f"  æœ€å¤§å›æ’¤: {result.max_drawdown:.2%}")
    
    # AI åˆ†æ
    try:
        analyzer = AIBacktestAnalyzer(api_key)
        
        print(f"\nAI åˆ†ææŠ¥å‘Š:")
        print("-" * 60)
        
        analysis = analyzer.analyze_result(result, "åŒå‡çº¿ç­–ç•¥")
        print(analysis)
        
        print("-" * 60)
        
        # å‚æ•°å»ºè®®
        print(f"\nAI å‚æ•°ä¼˜åŒ–å»ºè®®:")
        print("-" * 60)
        
        suggestion = analyzer.suggest_parameters(
            result,
            current_params={'short_window': 5, 'long_window': 20},
            param_ranges={'short_window': '3-10', 'long_window': '15-30'}
        )
        print(suggestion)
        
        print("-" * 60)
        
        print(f"\nâœ“ AI åˆ†æå®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âš ï¸  AI åˆ†æå¤±è´¥: {e}")
        return True  # ä¸å½±å“æ•´ä½“æµ‹è¯•


def test_strategy_comparison():
    """æµ‹è¯•ç­–ç•¥å¯¹æ¯”"""
    print("\n" + "="*60)
    print("æµ‹è¯• 4: å¤šç­–ç•¥å¯¹æ¯”")
    print("="*60)
    
    if not aq.is_core_loaded():
        print("âš ï¸  C++ æ¨¡å—æœªåŠ è½½ï¼Œè·³è¿‡")
        return True
    
    df = get_test_data()
    if df.empty:
        print("âŒ æ•°æ®ä¸è¶³")
        return False
    
    # æµ‹è¯•ä¸åŒå‚æ•°çš„ç­–ç•¥
    strategies = [
        ("MA(5,20)", MAStrategy(5, 20)),
        ("MA(10,30)", MAStrategy(10, 30)),
        ("MA(3,15)", MAStrategy(3, 15)),
    ]
    
    results = []
    runner = BacktestRunner(initial_capital=1000000.0)
    
    print(f"\nè¿è¡Œ {len(strategies)} ä¸ªç­–ç•¥...")
    
    for name, strategy in strategies:
        try:
            result = runner.run(strategy, df)
            results.append((name, result))
            
            print(f"\n{name}:")
            print(f"  æ”¶ç›Šç‡: {result.total_return:.2%}")
            print(f"  å¤æ™®: {result.sharpe_ratio:.3f}")
            print(f"  å›æ’¤: {result.max_drawdown:.2%}")
            print(f"  èƒœç‡: {result.win_rate:.2%}")
        except Exception as e:
            print(f"  âŒ å¤±è´¥: {e}")
    
    if results:
        # æ‰¾å‡ºæœ€ä½³ç­–ç•¥
        best = max(results, key=lambda x: x[1].sharpe_ratio)
        print(f"\næœ€ä½³ç­–ç•¥: {best[0]}")
        print(f"  å¤æ™®æ¯”ç‡: {best[1].sharpe_ratio:.3f}")
        
        print(f"\nâœ“ ç­–ç•¥å¯¹æ¯”å®Œæˆ")
        return True
    else:
        return False


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n")
    print("â•”" + "â•"*58 + "â•—")
    print("â•‘" + " "*10 + "ApexQuant Day 6 æµ‹è¯•" + " "*26 + "â•‘")
    print("â•š" + "â•"*58 + "â•")
    
    tests = [
        test_grid_search,
        test_monte_carlo,
        test_ai_analysis,
        test_strategy_comparison,
    ]
    
    passed = 0
    failed = 0
    
    for test_func in tests:
        try:
            if test_func():
                passed += 1
            else:
                failed += 1
        except Exception as e:
            failed += 1
            print(f"âŒ {test_func.__name__} å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)
    print(f"é€šè¿‡: {passed}/{len(tests)}")
    print(f"å¤±è´¥: {failed}/{len(tests)}")
    
    if failed == 0:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Day 6 ä»»åŠ¡å®Œæˆï¼")
        return True
    else:
        print(f"\nâš ï¸  æœ‰ {failed} ä¸ªæµ‹è¯•å¤±è´¥")
        return False


if __name__ == "__main__":
    os.environ['DEEPSEEK_API_KEY'] = 'sk-eea85ceb681c46a3bfbd4903a44ecc2d'
    
    success = run_all_tests()
    sys.exit(0 if success else 1)

