# ApexQuant æ”¹è¿›è¡ŒåŠ¨è®¡åˆ’

**åˆ¶å®šæ—¥æœŸ**: 2026-02-06  
**è®¡åˆ’å‘¨æœŸ**: 3ä¸ªæœˆ  
**ç›®æ ‡**: æå‡ç³»ç»Ÿå®‰å…¨æ€§ã€ç¨³å®šæ€§å’Œæ€§èƒ½

---

## ğŸ“… ç¬¬ä¸€å‘¨ - å®‰å…¨åŠ å›º (P0ç´§æ€¥)

### Day 1-2: APIå¯†é’¥ç®¡ç†

**ä»»åŠ¡:**
```bash
# 1. åˆ›å»º.envæ–‡ä»¶æ”¯æŒ
touch .env.example
echo "DEEPSEEK_API_KEY=your_key_here" > .env.example
echo "CLAUDE_API_KEY=your_key_here" >> .env.example
echo ".env" >> .gitignore

# 2. å®‰è£…python-dotenv
pip install python-dotenv

# 3. ä¿®æ”¹ai_advisor.py
```

**ä»£ç ä¿®æ”¹:**
```python
# python/apexquant/ai/deepseek_client.py
import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class DeepSeekClient:
    def __init__(self, api_key: str = None):
        # ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡
        self.api_key = api_key or os.getenv('DEEPSEEK_API_KEY')
        if not self.api_key:
            raise ValueError(
                "API key not found. Please set DEEPSEEK_API_KEY "
                "environment variable or pass api_key parameter."
            )
```

**éªŒè¯æ¸…å•:**
- [ ] .env.exampleå·²åˆ›å»º
- [ ] .gitignoreå·²æ›´æ–°
- [ ] ä»£ç å·²ä¿®æ”¹å¹¶æµ‹è¯•
- [ ] æ–‡æ¡£å·²æ›´æ–°è¯´æ˜

---

### Day 3-4: æ•°æ®åº“å¤‡ä»½æœºåˆ¶

**å®ç°ä»£ç :**
```python
# python/apexquant/simulation/database.py
import shutil
import os
from datetime import datetime, timedelta
from pathlib import Path

class DatabaseManager:
    def __init__(self, db_path: str):
        self.db_path = Path(db_path)
        self.backup_dir = self.db_path.parent / 'backups'
        self.backup_dir.mkdir(exist_ok=True)
    
    def backup(self) -> str:
        """åˆ›å»ºæ•°æ®åº“å¤‡ä»½"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_name = f"{self.db_path.stem}_{timestamp}.db"
        backup_path = self.backup_dir / backup_name
        
        if self.db_path.exists():
            shutil.copy2(self.db_path, backup_path)
            logger.info(f"Database backed up to {backup_path}")
            
            # æ¸…ç†æ—§å¤‡ä»½
            self._cleanup_old_backups(days=7)
            return str(backup_path)
        return None
    
    def _cleanup_old_backups(self, days: int = 7):
        """æ¸…ç†æ—§å¤‡ä»½æ–‡ä»¶"""
        cutoff = datetime.now() - timedelta(days=days)
        
        for backup_file in self.backup_dir.glob('*.db'):
            # ä»æ–‡ä»¶åè§£ææ—¶é—´æˆ³
            try:
                time_str = backup_file.stem.split('_')[-2:]
                file_time = datetime.strptime(
                    '_'.join(time_str), 
                    '%Y%m%d_%H%M%S'
                )
                
                if file_time < cutoff:
                    backup_file.unlink()
                    logger.info(f"Removed old backup: {backup_file}")
            except:
                continue
    
    def auto_backup_on_start(self):
        """å¯åŠ¨æ—¶è‡ªåŠ¨å¤‡ä»½"""
        last_backup_date = self._get_last_backup_date()
        today = datetime.now().date()
        
        if last_backup_date is None or last_backup_date < today:
            self.backup()
    
    def _get_last_backup_date(self):
        """è·å–æœ€åå¤‡ä»½æ—¥æœŸ"""
        backups = sorted(self.backup_dir.glob('*.db'), reverse=True)
        if backups:
            try:
                time_str = backups[0].stem.split('_')[-2:]
                return datetime.strptime(
                    '_'.join(time_str), 
                    '%Y%m%d_%H%M%S'
                ).date()
            except:
                pass
        return None

# åœ¨SimulationController.__init__ä¸­è°ƒç”¨
def __init__(self, ...):
    self.db = DatabaseManager(db_path)
    self.db.auto_backup_on_start()  # è‡ªåŠ¨å¤‡ä»½
```

**æµ‹è¯•ä»£ç :**
```python
# tests/test_database_backup.py
def test_database_backup():
    db = DatabaseManager("data/test_backup.db")
    
    # åˆ›å»ºå¤‡ä»½
    backup_path = db.backup()
    assert os.path.exists(backup_path)
    
    # æµ‹è¯•æ¸…ç†
    db._cleanup_old_backups(days=0)
```

**éªŒè¯æ¸…å•:**
- [ ] å¤‡ä»½åŠŸèƒ½å·²å®ç°
- [ ] è‡ªåŠ¨æ¸…ç†å·²å®ç°
- [ ] å¯åŠ¨æ—¶è‡ªåŠ¨å¤‡ä»½å·²å®ç°
- [ ] æµ‹è¯•å·²é€šè¿‡
- [ ] æ–‡æ¡£å·²æ›´æ–°

---

### Day 5-7: C++å¼‚å¸¸å¤„ç†

**ä¿®æ”¹æ–‡ä»¶: cpp/src/simulation/order_matcher.cpp**

```cpp
#include <stdexcept>
#include <sstream>
#include <cmath>

MatchResult OrderMatcher::try_match_order(
    const SimulatedOrder& order,
    const apexquant::Tick& tick,
    double available_volume
) {
    MatchResult result;
    result.success = false;
    result.filled_volume = 0;
    result.filled_price = 0.0;
    result.commission = 0.0;
    result.stamp_tax = 0.0;
    
    try {
        // 1. è¾“å…¥éªŒè¯
        if (order.volume <= 0) {
            throw std::invalid_argument(
                "Order volume must be positive"
            );
        }
        
        if (tick.last_price <= 0) {
            throw std::invalid_argument(
                "Invalid tick price"
            );
        }
        
        if (available_volume < 0) {
            throw std::invalid_argument(
                "Available volume cannot be negative"
            );
        }
        
        // 2. é˜²æ­¢é™¤é›¶
        if (std::abs(tick.last_price) < 1e-9) {
            result.reject_reason = "Price too close to zero";
            return result;
        }
        
        // 3. ä¸šåŠ¡é€»è¾‘
        // ... åŸæœ‰æ’®åˆé€»è¾‘ ...
        
        result.success = true;
        
    } catch (const std::invalid_argument& e) {
        result.reject_reason = std::string("Invalid argument: ") + e.what();
        // è®°å½•æ—¥å¿—ï¼ˆå¦‚æœæœ‰æ—¥å¿—ç³»ç»Ÿï¼‰
    } catch (const std::exception& e) {
        result.reject_reason = std::string("Error: ") + e.what();
    } catch (...) {
        result.reject_reason = "Unknown error occurred";
    }
    
    return result;
}

// æ·»åŠ è¾…åŠ©éªŒè¯å‡½æ•°
bool OrderMatcher::validate_order(
    const SimulatedOrder& order, 
    std::string& error_msg
) {
    if (order.volume <= 0) {
        error_msg = "Order volume must be positive";
        return false;
    }
    
    if (order.volume % 100 != 0) {
        error_msg = "Order volume must be multiple of 100";
        return false;
    }
    
    if (order.price < 0) {
        error_msg = "Order price cannot be negative";
        return false;
    }
    
    return true;
}
```

**æ·»åŠ æµ‹è¯•: cpp/tests/test_order_matcher.cpp**

```cpp
#include <catch2/catch.hpp>
#include "simulation/order_matcher.h"

TEST_CASE("OrderMatcher handles invalid inputs", "[order_matcher]") {
    OrderMatcher matcher(/* ... */);
    
    SECTION("Rejects zero volume") {
        SimulatedOrder order;
        order.volume = 0;  // Invalid
        
        auto result = matcher.try_match_order(order, tick, 1000);
        
        REQUIRE(result.success == false);
        REQUIRE(!result.reject_reason.empty());
    }
    
    SECTION("Rejects negative price") {
        Tick tick;
        tick.last_price = -10.0;  // Invalid
        
        auto result = matcher.try_match_order(order, tick, 1000);
        
        REQUIRE(result.success == false);
    }
}
```

**éªŒè¯æ¸…å•:**
- [ ] è¾“å…¥éªŒè¯å·²æ·»åŠ 
- [ ] å¼‚å¸¸æ•è·å·²å®ç°
- [ ] é™¤é›¶æ£€æŸ¥å·²æ·»åŠ 
- [ ] å•å…ƒæµ‹è¯•å·²æ·»åŠ 
- [ ] è¾¹ç•Œæ¡ä»¶å·²æµ‹è¯•

---

## ğŸ“… ç¬¬äºŒå‘¨ - æµ‹è¯•å®Œå–„ (P1é‡è¦)

### Day 8-10: C++å•å…ƒæµ‹è¯•

**å®‰è£…æµ‹è¯•æ¡†æ¶:**
```bash
# ä½¿ç”¨Catch2
git clone https://github.com/catchorg/Catch2.git external/Catch2
cd external/Catch2
cmake -B build -S . -DBUILD_TESTING=OFF
cmake --build build --target install
```

**ä¿®æ”¹CMakeLists.txt:**
```cmake
# æ·»åŠ æµ‹è¯•
enable_testing()
find_package(Catch2 3 REQUIRED)

add_executable(tests_cpp
    tests/test_order_matcher.cpp
    tests/test_simulation_account.cpp
    tests/test_simulated_exchange.cpp
)

target_link_libraries(tests_cpp 
    PRIVATE 
    apexquant_simulation
    Catch2::Catch2WithMain
)

include(Catch)
catch_discover_tests(tests_cpp)
```

**åˆ›å»ºæµ‹è¯•æ–‡ä»¶:**
```cpp
// tests/test_simulation_account.cpp
#include <catch2/catch_test_macros.hpp>
#include "simulation/simulation_account.h"

TEST_CASE("SimulationAccount basic operations") {
    SimulationAccount account("TEST001", 100000.0);
    
    SECTION("Initial state") {
        REQUIRE(account.get_available_cash() == 100000.0);
        REQUIRE(account.get_total_assets() == 100000.0);
    }
    
    SECTION("Freeze and unfreeze cash") {
        bool success = account.freeze_cash(10000.0);
        REQUIRE(success == true);
        REQUIRE(account.get_available_cash() == 90000.0);
        
        account.unfreeze_cash(10000.0);
        REQUIRE(account.get_available_cash() == 100000.0);
    }
    
    SECTION("Buy and sell operations") {
        // æµ‹è¯•ä¹°å…¥
        account.on_buy_filled("600519.SH", 100, 1800.0, 4.5, 0);
        
        auto positions = account.get_all_positions();
        REQUIRE(positions.size() == 1);
        REQUIRE(positions[0].volume == 100);
        
        // æµ‹è¯•T+1
        REQUIRE(positions[0].available_volume == 0);
        
        // æ›´æ–°åˆ°ä¸‹ä¸€å¤©
        account.update_daily("600519.SH");
        positions = account.get_all_positions();
        REQUIRE(positions[0].available_volume == 100);
    }
}
```

**è¿è¡Œæµ‹è¯•:**
```bash
cd build
cmake .. -DBUILD_TESTING=ON
cmake --build . --config Release
ctest -C Release --output-on-failure
```

---

### Day 11-14: Pythonæµ‹è¯•è¦†ç›–ç‡æå‡

**å®‰è£…è¦†ç›–ç‡å·¥å…·:**
```bash
pip install pytest-cov coverage
```

**åˆ›å»ºæµ‹è¯•é…ç½®: pytest.ini**
```ini
[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = 
    --verbose
    --cov=apexquant
    --cov-report=html
    --cov-report=term-missing
    --cov-fail-under=80
```

**è¡¥å……æµ‹è¯•æ–‡ä»¶:**

```python
# tests/test_performance_analyzer.py
import pytest
import pandas as pd
import numpy as np
from apexquant.simulation.performance_analyzer import PerformanceAnalyzer

@pytest.fixture
def sample_equity_curve():
    """ç”Ÿæˆæ ·æœ¬æƒç›Šæ›²çº¿"""
    dates = pd.date_range('2024-01-01', periods=100, freq='D')
    equity = 100000 * (1 + np.random.randn(100).cumsum() * 0.01)
    return pd.DataFrame({'date': dates, 'equity': equity})

@pytest.fixture
def sample_trades():
    """ç”Ÿæˆæ ·æœ¬äº¤æ˜“è®°å½•"""
    return [
        {'pnl': 1000, 'side': 'buy'},
        {'pnl': -500, 'side': 'sell'},
        {'pnl': 2000, 'side': 'buy'},
    ]

def test_calculate_metrics(sample_equity_curve, sample_trades):
    """æµ‹è¯•ç»©æ•ˆæŒ‡æ ‡è®¡ç®—"""
    analyzer = PerformanceAnalyzer(initial_capital=100000)
    metrics = analyzer.analyze(sample_equity_curve, sample_trades)
    
    assert metrics.total_trades == 3
    assert metrics.winning_trades == 2
    assert metrics.losing_trades == 1
    assert metrics.total_return != 0
    assert 0 <= metrics.win_rate <= 1

def test_max_drawdown_calculation(sample_equity_curve):
    """æµ‹è¯•æœ€å¤§å›æ’¤è®¡ç®—"""
    analyzer = PerformanceAnalyzer(initial_capital=100000)
    equity = sample_equity_curve['equity'].values
    
    max_dd = analyzer._calculate_max_drawdown(equity)
    
    assert 0 <= max_dd <= 1  # å›æ’¤åº”è¯¥åœ¨0-100%ä¹‹é—´
    assert isinstance(max_dd, float)

def test_plot_equity_curve(sample_equity_curve, tmp_path):
    """æµ‹è¯•æƒç›Šæ›²çº¿ç»˜åˆ¶"""
    analyzer = PerformanceAnalyzer(initial_capital=100000)
    save_path = tmp_path / "equity_curve.png"
    
    analyzer.plot_equity_curve(sample_equity_curve, str(save_path))
    
    assert save_path.exists()
    assert save_path.stat().st_size > 0

# tests/test_risk_manager.py
def test_risk_manager_position_limits():
    """æµ‹è¯•æŒä»“é™åˆ¶"""
    config = {
        'max_single_position_pct': 0.3,
        'max_total_position_pct': 0.95,
    }
    risk_mgr = RiskManager(config)
    
    # æµ‹è¯•å•åªè‚¡ç¥¨é™åˆ¶
    result = risk_mgr.check_order(
        symbol='600519.SH',
        side='BUY',
        price=100.0,
        volume=5000,  # 50ä¸‡ï¼Œè¶…è¿‡30%
        current_position=0,
        available_cash=800000,
        total_assets=1000000,
        current_positions={}
    )
    
    assert result.is_reject()
    assert 'position ratio' in result.reason.lower()

def test_risk_manager_daily_loss():
    """æµ‹è¯•æ—¥äºæŸé™åˆ¶"""
    config = {'daily_loss_limit_pct': 0.05}
    risk_mgr = RiskManager(config)
    
    # è®¾ç½®æ—¥åˆèµ„äº§
    risk_mgr.set_daily_start_assets(1000000)
    
    # æµ‹è¯•è¶…è¿‡5%äºæŸ
    result = risk_mgr._check_daily_loss_limit(940000)  # äºæŸ6%
    
    assert result.is_reject()
```

**è¿è¡Œæµ‹è¯•å¹¶ç”ŸæˆæŠ¥å‘Š:**
```bash
cd python
pytest --cov=apexquant --cov-report=html --cov-report=term-missing

# æŸ¥çœ‹HTMLæŠ¥å‘Š
# åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ htmlcov/index.html
```

**ç›®æ ‡è¦†ç›–ç‡:**
- æ€»ä½“è¦†ç›–ç‡: > 80%
- æ ¸å¿ƒæ¨¡å—: > 90%
- å·¥å…·æ¨¡å—: > 70%

---

## ğŸ“… ç¬¬ä¸‰-å››å‘¨ - æ—¥å¿—ä¸ç›‘æ§ (P1é‡è¦)

### Day 15-18: ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ

**Pythonç«¯æ”¹è¿›:**

```python
# python/apexquant/utils/logging_config.py
import logging
import sys
from pathlib import Path
from logging.handlers import RotatingFileHandler
import structlog

def setup_logging(
    log_dir: str = "logs",
    log_level: str = "INFO",
    enable_json: bool = False
):
    """é…ç½®ç»Ÿä¸€çš„æ—¥å¿—ç³»ç»Ÿ"""
    
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    log_path = Path(log_dir)
    log_path.mkdir(exist_ok=True)
    
    # é…ç½®æ ‡å‡†logging
    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        format='%(message)s',
        handlers=[
            # æ§åˆ¶å°è¾“å‡º
            logging.StreamHandler(sys.stdout),
            # æ–‡ä»¶è¾“å‡ºï¼ˆè½®è½¬ï¼‰
            RotatingFileHandler(
                log_path / 'apexquant.log',
                maxBytes=10*1024*1024,  # 10MB
                backupCount=5,
                encoding='utf-8'
            )
        ]
    )
    
    # é…ç½®structlog
    structlog.configure(
        processors=[
            structlog.stdlib.filter_by_level,
            structlog.stdlib.add_logger_name,
            structlog.stdlib.add_log_level,
            structlog.stdlib.PositionalArgumentsFormatter(),
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.StackInfoRenderer(),
            structlog.processors.format_exc_info,
            structlog.processors.UnicodeDecoder(),
            structlog.processors.JSONRenderer() if enable_json 
                else structlog.dev.ConsoleRenderer()
        ],
        context_class=dict,
        logger_factory=structlog.stdlib.LoggerFactory(),
        cache_logger_on_first_use=True,
    )

# ä½¿ç”¨ç¤ºä¾‹
from apexquant.utils.logging_config import setup_logging
import structlog

setup_logging(log_level='INFO', enable_json=False)
logger = structlog.get_logger()

# ç»“æ„åŒ–æ—¥å¿—
logger.info(
    "order_submitted",
    order_id="ORD001",
    symbol="600519.SH",
    volume=100,
    price=1800.0,
    side="BUY"
)
```

**C++ç«¯é›†æˆspdlog:**

```cpp
// cpp/include/utils/logger.h
#pragma once
#include <spdlog/spdlog.h>
#include <spdlog/sinks/rotating_file_sink.h>
#include <spdlog/sinks/stdout_color_sinks.h>
#include <memory>

namespace apexquant {

class Logger {
public:
    static void init(
        const std::string& log_dir = "logs",
        const std::string& log_level = "info"
    ) {
        try {
            // åˆ›å»ºå¤šä¸ªsink
            std::vector<spdlog::sink_ptr> sinks;
            
            // æ§åˆ¶å°sink
            auto console_sink = std::make_shared<
                spdlog::sinks::stdout_color_sink_mt
            >();
            console_sink->set_level(spdlog::level::info);
            sinks.push_back(console_sink);
            
            // æ–‡ä»¶sinkï¼ˆè½®è½¬ï¼‰
            auto file_sink = std::make_shared<
                spdlog::sinks::rotating_file_sink_mt
            >(
                log_dir + "/apexquant_cpp.log",
                1024 * 1024 * 10,  // 10MB
                3  // ä¿ç•™3ä¸ªæ–‡ä»¶
            );
            file_sink->set_level(spdlog::level::trace);
            sinks.push_back(file_sink);
            
            // åˆ›å»ºlogger
            auto logger = std::make_shared<spdlog::logger>(
                "apexquant", 
                sinks.begin(), 
                sinks.end()
            );
            
            // è®¾ç½®æ—¥å¿—çº§åˆ«
            logger->set_level(get_level(log_level));
            logger->set_pattern(
                "[%Y-%m-%d %H:%M:%S.%e] [%^%l%$] [%n] %v"
            );
            
            // è®¾ç½®ä¸ºé»˜è®¤logger
            spdlog::set_default_logger(logger);
            spdlog::flush_every(std::chrono::seconds(3));
            
        } catch (const spdlog::spdlog_ex& ex) {
            std::cerr << "Log init failed: " << ex.what() << std::endl;
        }
    }
    
    static spdlog::level::level_enum get_level(const std::string& level) {
        if (level == "trace") return spdlog::level::trace;
        if (level == "debug") return spdlog::level::debug;
        if (level == "info") return spdlog::level::info;
        if (level == "warn") return spdlog::level::warn;
        if (level == "error") return spdlog::level::err;
        return spdlog::level::info;
    }
};

}  // namespace apexquant

// ä¾¿æ·å®
#define LOG_TRACE(...) SPDLOG_TRACE(__VA_ARGS__)
#define LOG_DEBUG(...) SPDLOG_DEBUG(__VA_ARGS__)
#define LOG_INFO(...)  SPDLOG_INFO(__VA_ARGS__)
#define LOG_WARN(...)  SPDLOG_WARN(__VA_ARGS__)
#define LOG_ERROR(...) SPDLOG_ERROR(__VA_ARGS__)
```

**ä½¿ç”¨ç¤ºä¾‹:**

```cpp
#include "utils/logger.h"

int main() {
    // åˆå§‹åŒ–æ—¥å¿—
    apexquant::Logger::init("logs", "info");
    
    // ä½¿ç”¨æ—¥å¿—
    LOG_INFO("ApexQuant started");
    LOG_INFO("Initializing exchange with account_id={}, capital={}", 
        "SIM001", 100000.0);
    
    try {
        // ä¸šåŠ¡é€»è¾‘
    } catch (const std::exception& e) {
        LOG_ERROR("Error occurred: {}", e.what());
    }
    
    return 0;
}
```

---

### Day 19-21: æ€§èƒ½ç›‘æ§é›†æˆ

**å®‰è£…ä¾èµ–:**
```bash
pip install prometheus-client
```

**åˆ›å»ºç›‘æ§æ¨¡å—:**

```python
# python/apexquant/monitoring/metrics.py
from prometheus_client import (
    Counter, Histogram, Gauge, Summary, 
    start_http_server, CollectorRegistry
)
import functools
import time

class MetricsCollector:
    """æŒ‡æ ‡æ”¶é›†å™¨"""
    
    def __init__(self, port: int = 8000):
        self.registry = CollectorRegistry()
        self.port = port
        
        # è®¢å•æŒ‡æ ‡
        self.orders_total = Counter(
            'apexquant_orders_total',
            'Total number of orders',
            ['side', 'status', 'strategy'],
            registry=self.registry
        )
        
        self.order_latency = Histogram(
            'apexquant_order_latency_seconds',
            'Order processing latency',
            ['operation'],
            registry=self.registry
        )
        
        # äº¤æ˜“æŒ‡æ ‡
        self.trades_total = Counter(
            'apexquant_trades_total',
            'Total number of trades',
            ['symbol', 'side'],
            registry=self.registry
        )
        
        self.trade_value = Summary(
            'apexquant_trade_value',
            'Trade value in yuan',
            ['symbol'],
            registry=self.registry
        )
        
        # è´¦æˆ·æŒ‡æ ‡
        self.account_cash = Gauge(
            'apexquant_account_cash',
            'Available cash',
            ['account_id'],
            registry=self.registry
        )
        
        self.account_total_assets = Gauge(
            'apexquant_account_total_assets',
            'Total assets',
            ['account_id'],
            registry=self.registry
        )
        
        self.position_count = Gauge(
            'apexquant_position_count',
            'Number of positions',
            ['account_id'],
            registry=self.registry
        )
        
        # æ€§èƒ½æŒ‡æ ‡
        self.tick_processing_rate = Gauge(
            'apexquant_tick_processing_rate',
            'Ticks processed per second',
            registry=self.registry
        )
        
        self.backtest_duration = Histogram(
            'apexquant_backtest_duration_seconds',
            'Backtest duration',
            ['strategy'],
            registry=self.registry
        )
        
        # é£æ§æŒ‡æ ‡
        self.risk_violations = Counter(
            'apexquant_risk_violations_total',
            'Risk violations',
            ['type', 'symbol'],
            registry=self.registry
        )
        
        # AIæŒ‡æ ‡
        self.ai_calls = Counter(
            'apexquant_ai_calls_total',
            'AI API calls',
            ['model', 'status'],
            registry=self.registry
        )
        
        self.ai_latency = Histogram(
            'apexquant_ai_latency_seconds',
            'AI API latency',
            ['model'],
            registry=self.registry
        )
    
    def start_server(self):
        """å¯åŠ¨metricsæœåŠ¡å™¨"""
        start_http_server(self.port, registry=self.registry)
        print(f"Metrics server started on port {self.port}")
    
    def time_operation(self, operation: str):
        """æ“ä½œè®¡æ—¶è£…é¥°å™¨"""
        def decorator(func):
            @functools.wraps(func)
            def wrapper(*args, **kwargs):
                with self.order_latency.labels(
                    operation=operation
                ).time():
                    return func(*args, **kwargs)
            return wrapper
        return decorator

# å…¨å±€metricså®ä¾‹
metrics = MetricsCollector()

# ä½¿ç”¨ç¤ºä¾‹
@metrics.time_operation('submit_order')
def submit_order(self, order):
    # è®¢å•å¤„ç†é€»è¾‘
    metrics.orders_total.labels(
        side=order.side,
        status='submitted',
        strategy=self.strategy_name
    ).inc()
    
    # ...
    
    return result
```

**ä¿®æ”¹simulation_controller.pyé›†æˆç›‘æ§:**

```python
from apexquant.monitoring.metrics import metrics

class SimulationController:
    def __init__(self, ...):
        # ... åŸæœ‰åˆå§‹åŒ– ...
        
        # å¯åŠ¨ç›‘æ§æœåŠ¡å™¨
        if enable_monitoring:
            metrics.start_server()
    
    @metrics.time_operation('buy_order')
    def buy(self, symbol, volume, price=None):
        """ä¹°å…¥ï¼ˆå¸¦ç›‘æ§ï¼‰"""
        try:
            result = self._execute_buy(symbol, volume, price)
            
            # è®°å½•æŒ‡æ ‡
            metrics.orders_total.labels(
                side='buy',
                status='submitted',
                strategy=self.strategy_name
            ).inc()
            
            if result.success:
                metrics.trades_total.labels(
                    symbol=symbol,
                    side='buy'
                ).inc()
                
                metrics.trade_value.labels(
                    symbol=symbol
                ).observe(volume * price)
            
            return result
            
        except Exception as e:
            metrics.orders_total.labels(
                side='buy',
                status='error',
                strategy=self.strategy_name
            ).inc()
            raise
    
    def update_metrics(self):
        """æ›´æ–°è´¦æˆ·æŒ‡æ ‡"""
        account_info = self.get_account_info()
        
        metrics.account_cash.labels(
            account_id=self.account_id
        ).set(account_info['available_cash'])
        
        metrics.account_total_assets.labels(
            account_id=self.account_id
        ).set(account_info['total_assets'])
        
        metrics.position_count.labels(
            account_id=self.account_id
        ).set(len(account_info['positions']))
```

**åˆ›å»ºGrafana Dashboardé…ç½®:**

```yaml
# deployment/grafana/dashboards/apexquant.json
{
  "dashboard": {
    "title": "ApexQuant Monitoring",
    "panels": [
      {
        "title": "è®¢å•å¤„ç†é€Ÿç‡",
        "targets": [
          {
            "expr": "rate(apexquant_orders_total[1m])"
          }
        ]
      },
      {
        "title": "è´¦æˆ·èµ„äº§",
        "targets": [
          {
            "expr": "apexquant_account_total_assets"
          }
        ]
      },
      {
        "title": "è®¢å•å»¶è¿Ÿ",
        "targets": [
          {
            "expr": "histogram_quantile(0.99, apexquant_order_latency_seconds_bucket)"
          }
        ]
      }
    ]
  }
}
```

**éªŒè¯ç›‘æ§:**
```bash
# å¯åŠ¨åº”ç”¨
python run_simulation.py --enable-monitoring

# è®¿é—®metrics
curl http://localhost:8000/metrics

# è®¿é—®Grafana
# http://localhost:3000
```

---

## ğŸ“… ç¬¬äº”-å…«å‘¨ - æ€§èƒ½ä¼˜åŒ– (P2å»ºè®®)

### Week 5: Pythonæ€§èƒ½ä¼˜åŒ–

**ä½¿ç”¨numbaåŠ é€Ÿ:**

```python
# python/apexquant/simulation/performance_analyzer_optimized.py
from numba import jit
import numpy as np

@jit(nopython=True)
def calculate_drawdown_fast(equity: np.ndarray) -> float:
    """ä½¿ç”¨numbaåŠ é€Ÿçš„å›æ’¤è®¡ç®—"""
    n = len(equity)
    if n == 0:
        return 0.0
    
    max_dd = 0.0
    peak = equity[0]
    
    for i in range(1, n):
        if equity[i] > peak:
            peak = equity[i]
        
        dd = (peak - equity[i]) / peak
        if dd > max_dd:
            max_dd = dd
    
    return max_dd

@jit(nopython=True)
def calculate_sharpe_fast(
    returns: np.ndarray, 
    risk_free_rate: float = 0.03
) -> float:
    """åŠ é€Ÿçš„å¤æ™®æ¯”ç‡è®¡ç®—"""
    if len(returns) == 0:
        return 0.0
    
    mean_return = np.mean(returns) * 252
    std_return = np.std(returns) * np.sqrt(252)
    
    if std_return == 0:
        return 0.0
    
    return (mean_return - risk_free_rate) / std_return

# æ€§èƒ½å¯¹æ¯”
import timeit

# æµ‹è¯•æ•°æ®
equity = np.random.randn(100000).cumsum() + 100000

# åŸå§‹æ–¹æ³•
t1 = timeit.timeit(
    lambda: calculate_drawdown_original(equity),
    number=100
)

# ä¼˜åŒ–æ–¹æ³•
t2 = timeit.timeit(
    lambda: calculate_drawdown_fast(equity),
    number=100
)

print(f"åŸå§‹æ–¹æ³•: {t1:.4f}s")
print(f"ä¼˜åŒ–æ–¹æ³•: {t2:.4f}s")
print(f"åŠ é€Ÿæ¯”: {t1/t2:.2f}x")
```

---

## ğŸ“Š è¿›åº¦è·Ÿè¸ª

### å®Œæˆæ ‡å‡†

æ¯é¡¹ä»»åŠ¡å®Œæˆåéœ€è¦æ»¡è¶³:
- [ ] ä»£ç å·²å®ç°å¹¶é€šè¿‡review
- [ ] æµ‹è¯•å·²ç¼–å†™å¹¶é€šè¿‡
- [ ] æ–‡æ¡£å·²æ›´æ–°
- [ ] å·²éƒ¨ç½²åˆ°æµ‹è¯•ç¯å¢ƒ
- [ ] æ€§èƒ½ç¬¦åˆé¢„æœŸ

### æ¯å‘¨å›é¡¾

**æ¯å‘¨äº”è¿›è¡Œå›é¡¾ä¼šè®®:**
1. å›é¡¾æœ¬å‘¨å®Œæˆçš„ä»»åŠ¡
2. è¯„ä¼°é‡åˆ°çš„é—®é¢˜
3. è°ƒæ•´ä¸‹å‘¨è®¡åˆ’
4. æ›´æ–°æ­¤æ–‡æ¡£

---

## ğŸ¯ æˆåŠŸæŒ‡æ ‡

**ç¬¬ä¸€å‘¨ç»“æŸ:**
- [ ] æ‰€æœ‰P0å®‰å…¨é—®é¢˜å·²è§£å†³
- [ ] ä»£ç å·²æäº¤åˆ°git

**ç¬¬äºŒå‘¨ç»“æŸ:**
- [ ] C++æµ‹è¯•è¦†ç›–ç‡ > 70%
- [ ] Pythonæµ‹è¯•è¦†ç›–ç‡ > 80%

**ç¬¬å››å‘¨ç»“æŸ:**
- [ ] æ—¥å¿—ç³»ç»Ÿç»Ÿä¸€
- [ ] ç›‘æ§Dashboardå¯ç”¨

**ç¬¬å…«å‘¨ç»“æŸ:**
- [ ] æ€§èƒ½æå‡50%+
- [ ] æ‰€æœ‰P1é—®é¢˜å·²è§£å†³

---

**åˆ¶å®šäºº**: AI Assistant  
**å®¡æ‰¹äºº**: é¡¹ç›®è´Ÿè´£äºº  
**æœ€åæ›´æ–°**: 2026-02-06

